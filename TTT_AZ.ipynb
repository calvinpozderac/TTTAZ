{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkB2WbEBKEIodESwmBfy2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calvinpozderac/TTTAZ/blob/main/TTT_AZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "import math\n",
        "import random\n",
        "from collections import deque, defaultdict\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Rw9u5MvSll",
        "outputId": "aab57e6b-47cd-4027-99d5-0f738ccfe4b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optimal AI ---\n",
        "# Implementing a perfect AI for a new game might be challenging or impossible\n",
        "# for complex games due to the state space size. For simple games like Tic-Tac-Toe,\n",
        "# a minimax implementation is feasible for evaluation.\n",
        "class OptimalAI:\n",
        "    \"\"\"Perfect minimax AI for Tic-Tac-Toe with caching\"\"\"\n",
        "\n",
        "    def __init__(self, game):\n",
        "        self.game = game\n",
        "        self.minimax_cache = {}  # Cache for minimax values\n",
        "        self.move_cache = {}     # Cache for best moves\n",
        "        self.precompute_all_positions()\n",
        "\n",
        "    def precompute_all_positions(self):\n",
        "        \"\"\"Precompute all possible positions for instant lookup\"\"\"\n",
        "        print(\"Precomputing optimal moves for all positions...\")\n",
        "\n",
        "        def generate_all_states(state, player):\n",
        "            \"\"\"Recursively generate and evaluate all possible game states\"\"\"\n",
        "            # Use a more robust string representation for state keys\n",
        "            state_key = (np.array2string(state.flatten(), separator=',', max_line_width=np.inf), player)\n",
        "\n",
        "            if state_key in self.minimax_cache:\n",
        "                return\n",
        "\n",
        "            # Check if game is over\n",
        "            result = self.game.get_game_ended(state, 1) # Evaluate from player 1's perspective\n",
        "            if result is not None:\n",
        "                # Store the result from the perspective of the current player\n",
        "                self.minimax_cache[state_key] = result * player\n",
        "                return\n",
        "\n",
        "            # Find best move and value for this position\n",
        "            best_score = float('-inf') if player == 1 else float('inf')\n",
        "            best_move = None\n",
        "\n",
        "            for action in range(9):\n",
        "                if state.flatten()[action] == 0:\n",
        "                    next_state, next_player = self.game.get_next_state(state, action, player)\n",
        "\n",
        "                    # Recursively evaluate next state\n",
        "                    generate_all_states(next_state, next_player)\n",
        "\n",
        "                    next_state_key = (np.array2string(next_state.flatten(), separator=',', max_line_width=np.inf), next_player)\n",
        "                    score = self.minimax_cache[next_state_key] * next_player # Get score from current player's perspective\n",
        "\n",
        "                    if player == 1 and score > best_score:\n",
        "                        best_score = score\n",
        "                        best_move = action\n",
        "                    elif player == -1 and score < best_score:\n",
        "                        best_score = score\n",
        "                        best_move = action\n",
        "\n",
        "            # Cache the results\n",
        "            self.minimax_cache[state_key] = best_score\n",
        "            self.move_cache[state_key] = best_move\n",
        "\n",
        "        # Generate all states starting from empty board\n",
        "        initial_state = self.game.get_initial_state()\n",
        "        generate_all_states(initial_state, 1)\n",
        "\n",
        "        print(f\"Precomputed {len(self.move_cache)} positions\")\n",
        "\n",
        "    def minimax(self, state, depth, maximizing_player):\n",
        "        \"\"\"Minimax with caching (alpha-beta pruning removed)\"\"\"\n",
        "        # Use a more robust string representation for state keys\n",
        "        state_key = (np.array2string(state.flatten(), separator=',', max_line_width=np.inf), 1 if maximizing_player else -1)\n",
        "\n",
        "\n",
        "        if state_key in self.minimax_cache:\n",
        "            return self.minimax_cache[state_key]\n",
        "\n",
        "        result = self.game.get_game_ended(state, 1 if maximizing_player else -1)\n",
        "\n",
        "        if result is not None:\n",
        "            self.minimax_cache[state_key] = result * (1 if maximizing_player else -1) # Store from current player's perspective\n",
        "            return self.minimax_cache[state_key]\n",
        "\n",
        "        if maximizing_player:\n",
        "            max_eval = float('-inf')\n",
        "            for action in range(9):\n",
        "                if state.flatten()[action] == 0:\n",
        "                    next_state, _ = self.game.get_next_state(state, action, 1)\n",
        "                    eval_score = self.minimax(next_state, depth + 1, False)\n",
        "                    max_eval = max(max_eval, eval_score)\n",
        "            self.minimax_cache[state_key] = max_eval\n",
        "            return max_eval\n",
        "        else:\n",
        "            min_eval = float('inf')\n",
        "            for action in range(9):\n",
        "                if state.flatten()[action] == 0:\n",
        "                    next_state, _ = self.game.get_next_state(state, action, -1)\n",
        "                    eval_score = self.minimax(next_state, depth + 1, True)\n",
        "                    min_eval = min(min_eval, eval_score)\n",
        "            self.minimax_cache[state_key] = min_eval\n",
        "            return min_eval\n",
        "\n",
        "    def get_best_move(self, state, player):\n",
        "        \"\"\"Get the optimal move using cached results\"\"\"\n",
        "        # Use a more robust string representation for state keys\n",
        "        state_key = (np.array2string(state.flatten(), separator=',', max_line_width=np.inf), player)\n",
        "\n",
        "\n",
        "        # Use precomputed move if available\n",
        "        if state_key in self.move_cache:\n",
        "            return self.move_cache[state_key]\n",
        "\n",
        "        # Fallback to real-time computation (shouldn't happen after precompute)\n",
        "        print(f\"Warning: Position {state_key} not in cache, computing real-time for player {player}\")\n",
        "        best_score = float('-inf') if player == 1 else float('inf')\n",
        "        best_move = None\n",
        "\n",
        "        for action in range(9):\n",
        "            if state.flatten()[action] == 0:\n",
        "                next_state, _ = self.game.get_next_state(state, action, player)\n",
        "                score = self.minimax(next_state, 0, player == 1) # Use player == 1 to get score from player 1's perspective\n",
        "\n",
        "                if player == 1 and score > best_score:\n",
        "                    best_score = score\n",
        "                    best_move = action\n",
        "                elif player == -1 and score < best_score:\n",
        "                    best_score = score\n",
        "                    best_move = action\n",
        "\n",
        "        return best_move"
      ],
      "metadata": {
        "id": "Us82vg6IvSOG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "npjJZOAAjpsx"
      },
      "outputs": [],
      "source": [
        "# --- Game Class ---\n",
        "# To extend to a new game, create a new class inheriting from a base Game class\n",
        "# (or simply implement the required methods) that defines the game rules:\n",
        "# - get_initial_state(): returns the starting board state\n",
        "# - get_valid_moves(state): returns a boolean array of valid moves from the state\n",
        "# - get_next_state(state, action, player): returns the next state and player after an action\n",
        "# - get_game_ended(state, player): returns 1 for win, -1 for loss, 0 for draw, None if game continues\n",
        "# - get_canonical_form(state, player): returns state from the perspective of player 1\n",
        "# - get_symmetries(state, pi): returns a list of (state, policy) tuples representing board symmetries for data augmentation\n",
        "class TicTacToeGame:\n",
        "    \"\"\"Optimized Tic-Tac-Toe game implementation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.board_size = 3\n",
        "        self.action_size = 9  # 3x3 board\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return np.zeros((3, 3), dtype=np.int8)\n",
        "\n",
        "    def get_valid_moves(self, state):\n",
        "        return (state == 0).flatten()\n",
        "\n",
        "    def get_next_state(self, state, action, player):\n",
        "        next_state = state.copy()\n",
        "        row, col = action // 3, action % 3\n",
        "        next_state[row, col] = player\n",
        "        return next_state, -player  # Switch player\n",
        "\n",
        "    def get_game_ended(self, state, player):\n",
        "        # Check rows\n",
        "        for row in range(3):\n",
        "            if abs(sum(state[row])) == 3:\n",
        "                return sum(state[row]) / 3  # Returns 1 or -1\n",
        "\n",
        "        # Check columns\n",
        "        for col in range(3):\n",
        "            if abs(sum(state[:, col])) == 3:\n",
        "                return sum(state[:, col]) / 3\n",
        "\n",
        "        # Check diagonals\n",
        "        if abs(sum(state.diagonal())) == 3:\n",
        "            return sum(state.diagonal()) / 3\n",
        "        if abs(sum(np.fliplr(state).diagonal())) == 3:\n",
        "            return sum(np.fliplr(state).diagonal()) / 3\n",
        "\n",
        "        # Check for draw\n",
        "        if not (state == 0).any():\n",
        "            return 0\n",
        "\n",
        "        return None  # Game continues\n",
        "\n",
        "    def get_canonical_form(self, state, player):\n",
        "        return state * player\n",
        "\n",
        "    def get_symmetries(self, state, pi):\n",
        "        \"\"\"Get all symmetries for data augmentation\"\"\"\n",
        "        symmetries = []\n",
        "\n",
        "        # Original\n",
        "        symmetries.append((state, pi))\n",
        "\n",
        "        # Rotations\n",
        "        for k in range(1, 4):\n",
        "            state_rot = np.rot90(state, k)\n",
        "            pi_rot = np.rot90(pi.reshape(3, 3), k).flatten()\n",
        "            symmetries.append((state_rot, pi_rot))\n",
        "\n",
        "        # Flips\n",
        "        state_flip = np.fliplr(state)\n",
        "        pi_flip = np.fliplr(pi.reshape(3, 3)).flatten()\n",
        "        symmetries.append((state_flip, pi_flip))\n",
        "\n",
        "        # Rotations of flipped\n",
        "        for k in range(1, 4):\n",
        "            state_rot = np.rot90(state_flip, k)\n",
        "            pi_rot = np.rot90(pi_flip.reshape(3, 3), k).flatten()\n",
        "            symmetries.append((state_rot, pi_rot))\n",
        "\n",
        "        return symmetries\n",
        "\n",
        "# --- Neural Network ---\n",
        "# To extend to a new game, adjust the network architecture:\n",
        "# - Input shape: Match the new game's board representation.\n",
        "# - Output shapes: Match the new game's action space (policy head) and value output (value head).\n",
        "# - Consider different convolutional filter sizes or types if the board structure is very different.\n",
        "class NeuralNetwork(nn.Module):\n",
        "    \"\"\"Optimized neural network for AlphaZero\"\"\"\n",
        "\n",
        "    def __init__(self, game, num_channels=512):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.board_size = game.board_size\n",
        "        self.action_size = game.action_size\n",
        "        self.num_channels = num_channels\n",
        "\n",
        "        # Convolutional layers (adjust kernel size/padding if board size changes significantly)\n",
        "        self.conv1 = nn.Conv2d(1, num_channels, 3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels, 3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(num_channels, num_channels, 3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(num_channels, num_channels, 3, stride=1, padding=1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn3 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn4 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "        # Policy head (adjust output size to game.action_size)\n",
        "        self.conv_policy = nn.Conv2d(num_channels, 32, 1)\n",
        "        self.bn_policy = nn.BatchNorm2d(32)\n",
        "        self.fc_policy = nn.Linear(32 * self.board_size * self.board_size, self.action_size)\n",
        "\n",
        "        # Value head (adjust input size if board size changes)\n",
        "        self.conv_value = nn.Conv2d(num_channels, 3, 1)\n",
        "        self.bn_value = nn.BatchNorm2d(3)\n",
        "        self.fc_value1 = nn.Linear(3 * self.board_size * self.board_size, 64)\n",
        "        self.fc_value2 = nn.Linear(64, 1)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, s):\n",
        "        # Common layers\n",
        "        s = s.view(-1, 1, self.board_size, self.board_size)\n",
        "        s = F.relu(self.bn1(self.conv1(s)))\n",
        "        s = F.relu(self.bn2(self.conv2(s)))\n",
        "        s = F.relu(self.bn3(self.conv3(s)))\n",
        "        s = F.relu(self.bn4(self.conv4(s)))\n",
        "\n",
        "        # Policy head\n",
        "        pi = F.relu(self.bn_policy(self.conv_policy(s)))\n",
        "        pi = pi.view(pi.size(0), -1)\n",
        "        pi = self.dropout(pi)\n",
        "        pi = self.fc_policy(pi)\n",
        "        pi = F.log_softmax(pi, dim=1)\n",
        "\n",
        "        # Value head\n",
        "        v = F.relu(self.bn_value(self.conv_value(s)))\n",
        "        v = v.view(v.size(0), -1)\n",
        "        v = self.dropout(v)\n",
        "        v = F.relu(self.fc_value1(v))\n",
        "        v = self.fc_value2(v)\n",
        "        v = torch.tanh(v)\n",
        "\n",
        "        return pi, v\n",
        "\n",
        "# --- MCTS ---\n",
        "# The MCTS class is generally game-agnostic, relying on the Game and NeuralNetwork classes.\n",
        "# No major changes needed here for a new game unless the MCTS algorithm itself needs modification\n",
        "# (e.g., for games with very large branching factors).\n",
        "class MCTS:\n",
        "    \"\"\"Optimized Monte Carlo Tree Search\"\"\"\n",
        "\n",
        "    def __init__(self, game, nnet, args):\n",
        "        self.game = game\n",
        "        self.nnet = nnet\n",
        "        self.args = args\n",
        "        self.Qsa = {}  # Q values\n",
        "        self.Nsa = {}  # Visit counts for state-action\n",
        "        self.Ns = {}   # Visit counts for state\n",
        "        self.Ps = {}   # Policy\n",
        "        self.Es = {}   # Game ended\n",
        "        self.Vs = {}   # Valid moves\n",
        "\n",
        "    def get_action_prob(self, state, temp=1):\n",
        "        \"\"\"Get action probabilities and value estimate after MCTS simulations\"\"\"\n",
        "        for _ in range(self.args.num_mcts_sims):\n",
        "            self.search(state, 1)\n",
        "\n",
        "        s = self.game.get_canonical_form(state, 1)\n",
        "        # Use a more robust string representation for state keys\n",
        "        s_str = np.array2string(s, separator=',', max_line_width=np.inf)\n",
        "        counts = [self.Nsa.get((s_str, a), 0) for a in range(self.game.action_size)]\n",
        "\n",
        "        if temp == 0:\n",
        "            # Deterministic - choose best action\n",
        "            best_actions = np.array(np.argwhere(counts == np.max(counts))).flatten()\n",
        "            best_action = np.random.choice(best_actions)\n",
        "            probs = np.zeros(len(counts))\n",
        "            probs[best_action] = 1\n",
        "        else:\n",
        "            # Probabilistic based on temperature\n",
        "            counts = np.array(counts, dtype=np.float64)\n",
        "            counts = counts ** (1.0 / temp)\n",
        "            probs = counts / counts.sum()\n",
        "\n",
        "        # Calculate MCTS value estimate\n",
        "        # Weighted average of action values based on visit counts\n",
        "        total_visits = sum(counts)\n",
        "        if total_visits > 0:\n",
        "            mcts_value = 0\n",
        "            for a in range(self.game.action_size):\n",
        "                if (s_str, a) in self.Qsa and counts[a] > 0:\n",
        "                    mcts_value += (counts[a] / total_visits) * self.Qsa[(s_str, a)]\n",
        "        else:\n",
        "            mcts_value = 0\n",
        "\n",
        "        return probs, mcts_value\n",
        "\n",
        "    def search(self, state, player):\n",
        "        \"\"\"MCTS search with neural network guidance\"\"\"\n",
        "        s = self.game.get_canonical_form(state, player)\n",
        "        # Use a more robust string representation for state keys\n",
        "        s_str = np.array2string(s, separator=',', max_line_width=np.inf)\n",
        "\n",
        "\n",
        "        if s_str not in self.Es:\n",
        "            self.Es[s_str] = self.game.get_game_ended(s, 1) # Evaluate from player 1's perspective\n",
        "\n",
        "        if self.Es[s_str] is not None:\n",
        "            # Terminal node\n",
        "            return self.Es[s_str] # Return the game result directly\n",
        "\n",
        "        if s_str not in self.Ps:\n",
        "            # Leaf node - expand using neural network\n",
        "            with torch.no_grad():\n",
        "                # Ensure input tensor has the correct shape (batch, channels, height, width)\n",
        "                s_tensor = torch.FloatTensor(s).unsqueeze(0).unsqueeze(0).to(device)\n",
        "                log_pi, v = self.nnet(s_tensor)\n",
        "                pi = torch.exp(log_pi).cpu().numpy()[0]\n",
        "\n",
        "            valid_moves = self.game.get_valid_moves(s)\n",
        "            pi = pi * valid_moves  # Mask invalid moves\n",
        "            pi_sum = np.sum(pi)\n",
        "            if pi_sum > 0:\n",
        "                pi = pi / pi_sum  # Renormalize\n",
        "            else:\n",
        "                # If all valid moves have zero probability, distribute probability evenly\n",
        "                pi = valid_moves / np.sum(valid_moves)\n",
        "\n",
        "            self.Ps[s_str] = pi\n",
        "            self.Vs[s_str] = valid_moves\n",
        "            self.Ns[s_str] = 0\n",
        "            return v.item() # Return the value estimate\n",
        "\n",
        "        # Internal node - select action using UCB\n",
        "        valid_moves = self.Vs[s_str]\n",
        "        cur_best = -float('inf')\n",
        "        best_act = -1\n",
        "\n",
        "        # UCB formula\n",
        "        for a in range(self.game.action_size):\n",
        "            if valid_moves[a]:\n",
        "                if (s_str, a) in self.Qsa:\n",
        "                    u = (self.Qsa[(s_str, a)] +\n",
        "                         self.args.cpuct * self.Ps[s_str][a] *\n",
        "                         math.sqrt(self.Ns[s_str]) / (1 + self.Nsa[(s_str, a)]))\n",
        "                else:\n",
        "                    u = (self.args.cpuct * self.Ps[s_str][a] *\n",
        "                         math.sqrt(self.Ns[s_str] + 1e-8)) # Add epsilon to prevent division by zero\n",
        "\n",
        "                if u > cur_best:\n",
        "                    cur_best = u\n",
        "                    best_act = a\n",
        "\n",
        "        # Make move and recurse\n",
        "        next_s, next_player = self.game.get_next_state(state, best_act, player) # Use original state here\n",
        "        v = self.search(next_s, next_player)\n",
        "\n",
        "        # Backup\n",
        "        if (s_str, best_act) in self.Qsa:\n",
        "            self.Qsa[(s_str, best_act)] = ((self.Nsa[(s_str, best_act)] *\n",
        "                                          self.Qsa[(s_str, best_act)] + v) /\n",
        "                                         (self.Nsa[(s_str, best_act)] + 1))\n",
        "            self.Nsa[(s_str, best_act)] += 1\n",
        "        else:\n",
        "            self.Qsa[(s_str, best_act)] = v\n",
        "            self.Nsa[(s_str, best_act)] = 1\n",
        "\n",
        "        self.Ns[s_str] += 1\n",
        "        return v\n",
        "\n",
        "# --- Training Arguments ---\n",
        "# Adjust these parameters based on the complexity of the new game.\n",
        "# More complex games may require more simulations, episodes, iterations, and a larger batch size.\n",
        "class Args:\n",
        "    \"\"\"Training arguments\"\"\"\n",
        "    def __init__(self):\n",
        "        # Self-play\n",
        "        self.num_iters = 100\n",
        "        self.num_eps = 50  # Episodes per iteration\n",
        "        self.temp_threshold = 15 # Number of moves to use temperature sampling in self-play\n",
        "\n",
        "        # MCTS\n",
        "        self.num_mcts_sims = 250 # Number of MCTS simulations per move\n",
        "        self.cpuct = 1.0 # Exploration constant\n",
        "\n",
        "        # Training\n",
        "        self.epochs = 50\n",
        "        self.batch_size = 512\n",
        "        self.lr = 0.001\n",
        "        self.dropout = 0.3\n",
        "        self.weight_decay = 1e-4\n",
        "\n",
        "        # Memory\n",
        "        self.max_memory_size = 100000 # Maximum number of training examples\n",
        "\n",
        "        # Evaluation\n",
        "        self.arena_compare = 40 # Number of games to compare new vs old network\n",
        "        self.update_threshold = 0.6 # Minimum win rate against old network to update\n",
        "\n",
        "# --- AlphaZero Trainer ---\n",
        "# The trainer orchestrates self-play, training, and evaluation.\n",
        "# Mostly game-agnostic, but requires the Game, NeuralNetwork, MCTS, and Args classes.\n",
        "class AlphaZeroTrainer:\n",
        "    \"\"\"Main AlphaZero trainer\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.game = TicTacToeGame()\n",
        "        self.args = Args()\n",
        "        self.nnet = NeuralNetwork(self.game).to(device)\n",
        "        self.optimizer = optim.Adam(self.nnet.parameters(), lr=self.args.lr,\n",
        "                                   weight_decay=self.args.weight_decay)\n",
        "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=30, gamma=0.1)\n",
        "        self.scaler = GradScaler('cuda')\n",
        "\n",
        "        self.train_examples_history = deque([], maxlen=self.args.max_memory_size // self.args.num_eps) # Store examples from recent episodes\n",
        "        self.optimal_ai = OptimalAI(self.game)\n",
        "\n",
        "        # Training metrics\n",
        "        self.loss_history = []\n",
        "        self.tie_rate_history = []\n",
        "\n",
        "    def execute_episode(self):\n",
        "        \"\"\"Execute one episode of self-play\"\"\"\n",
        "        train_examples = []\n",
        "        state = self.game.get_initial_state()\n",
        "        current_player = 1\n",
        "        episode_step = 0\n",
        "\n",
        "        while True:\n",
        "            episode_step += 1\n",
        "            canonical_state = self.game.get_canonical_form(state, current_player)\n",
        "            temp = int(episode_step < self.args.temp_threshold)\n",
        "\n",
        "            # Get action probabilities and value estimate from MCTS\n",
        "            mcts = MCTS(self.game, self.nnet, self.args)\n",
        "            pi, mcts_value = mcts.get_action_prob(canonical_state, temp=temp)\n",
        "\n",
        "            # Store training example with MCTS value as target\n",
        "            sym = self.game.get_symmetries(canonical_state, pi)\n",
        "            for s, p in sym:\n",
        "                # Use MCTS value estimate as the target (from current player's perspective)\n",
        "                train_examples.append([s, current_player, p, mcts_value * current_player])\n",
        "\n",
        "            # Sample action from probabilities\n",
        "            action = np.random.choice(len(pi), p=pi)\n",
        "\n",
        "            # Make move\n",
        "            state, current_player = self.game.get_next_state(state, action, current_player)\n",
        "\n",
        "            # Check if game ended\n",
        "            result = self.game.get_game_ended(state, current_player)\n",
        "            if result is not None:\n",
        "                # Game ended - training examples already have MCTS values as targets\n",
        "                return train_examples\n",
        "\n",
        "    def train(self, examples):\n",
        "        \"\"\"Train the neural network\"\"\"\n",
        "        random.shuffle(examples)\n",
        "\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        self.nnet.train() # Set model to training mode\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            batch_idx = 0\n",
        "\n",
        "            while batch_idx < len(examples):\n",
        "                batch_examples = examples[batch_idx:batch_idx + self.args.batch_size]\n",
        "                batch_idx += self.args.batch_size\n",
        "\n",
        "                # Ensure input tensor has the correct shape (batch, channels, height, width)\n",
        "                boards = torch.FloatTensor(np.array([ex[0] for ex in batch_examples])).unsqueeze(1).to(device)\n",
        "                target_pis = torch.FloatTensor(np.array([ex[2] for ex in batch_examples])).to(device)\n",
        "                target_vs = torch.FloatTensor(np.array([ex[3] for ex in batch_examples])).to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                with autocast('cuda'):\n",
        "                    out_pi, out_v = self.nnet(boards)\n",
        "                    l_pi = self.loss_pi(target_pis, out_pi)\n",
        "                    l_v = self.loss_v(target_vs, out_v)\n",
        "                    total_loss_batch = l_pi + l_v\n",
        "\n",
        "                self.scaler.scale(total_loss_batch).backward()\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "\n",
        "                total_loss += total_loss_batch.item()\n",
        "                num_batches += 1\n",
        "\n",
        "        self.scheduler.step()\n",
        "        avg_loss = total_loss / num_batches\n",
        "        self.loss_history.append(avg_loss)\n",
        "        return avg_loss\n",
        "\n",
        "    def loss_pi(self, targets, outputs):\n",
        "        return -torch.sum(targets * outputs) / targets.size()[0]\n",
        "\n",
        "    def loss_v(self, targets, outputs):\n",
        "        return torch.sum((targets - outputs.view(-1)) ** 2) / targets.size()[0]\n",
        "\n",
        "    def evaluate_against_optimal(self, num_games=10):\n",
        "        \"\"\"Evaluate AlphaZero against optimal minimax AI\"\"\"\n",
        "        self.nnet.eval() # Set model to evaluation mode\n",
        "\n",
        "        wins = 0\n",
        "        draws = 0\n",
        "        losses = 0\n",
        "\n",
        "        for game_num in range(num_games):\n",
        "            state = self.game.get_initial_state()\n",
        "            current_player = 1\n",
        "\n",
        "            # AlphaZero plays as player 1 half the time\n",
        "            alphazero_player = 1 if game_num < num_games // 2 else -1\n",
        "\n",
        "            while True:\n",
        "                if current_player == alphazero_player:\n",
        "                    # AlphaZero's turn\n",
        "                    mcts = MCTS(self.game, self.nnet, self.args)\n",
        "                    canonical_state = self.game.get_canonical_form(state, current_player)\n",
        "                    # Get action probabilities with temp=0 for deterministic play\n",
        "                    pi, _ = mcts.get_action_prob(canonical_state, temp=0)\n",
        "                    action = np.argmax(pi)\n",
        "                else:\n",
        "                    # Optimal AI's turn\n",
        "                    action = self.optimal_ai.get_best_move(state, current_player)\n",
        "\n",
        "                state, current_player = self.game.get_next_state(state, action, current_player)\n",
        "\n",
        "                result = self.game.get_game_ended(state, 1) # Evaluate from player 1's perspective\n",
        "                if result is not None:\n",
        "                    # Check result from AlphaZero's perspective\n",
        "                    if result == alphazero_player:\n",
        "                        wins += 1\n",
        "                    elif result == -alphazero_player:\n",
        "                        losses += 1\n",
        "                    else: # result is 0\n",
        "                        draws += 1\n",
        "                    break\n",
        "\n",
        "        tie_rate = draws / num_games\n",
        "        self.tie_rate_history.append(tie_rate)\n",
        "        return wins, draws, losses, tie_rate\n",
        "\n",
        "    def learn(self):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        print(\"Starting AlphaZero training...\")\n",
        "\n",
        "        for i in range(1, self.args.num_iters + 1):\n",
        "            print(f\"\\n=== Iteration {i}/{self.args.num_iters} ===\")\n",
        "\n",
        "            # Self-play\n",
        "            iteration_train_examples = deque([], maxlen=self.args.max_memory_size)\n",
        "\n",
        "            print(\"Collecting self-play games...\")\n",
        "            for eps in range(self.args.num_eps):\n",
        "                iteration_train_examples.extend(self.execute_episode()) # Use extend\n",
        "                if (eps + 1) % 10 == 0: # Print progress less frequently\n",
        "                    print(f\"Episode {eps + 1}/{self.args.num_eps}\")\n",
        "\n",
        "            # Add to training history\n",
        "            self.train_examples_history.append(iteration_train_examples)\n",
        "\n",
        "            # Prepare training data from history\n",
        "            train_examples = []\n",
        "            for e in self.train_examples_history:\n",
        "                train_examples.extend(e)\n",
        "\n",
        "            # Train\n",
        "            print(f\"Training on {len(train_examples)} examples...\")\n",
        "            avg_loss = self.train(train_examples)\n",
        "            print(f\"Average loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # Evaluate every iteration\n",
        "            print(\"Evaluating against optimal AI...\")\n",
        "            wins, draws, losses, tie_rate = self.evaluate_against_optimal()\n",
        "            print(f\"Results: {wins}W-{draws}D-{losses}L (Tie rate: {tie_rate:.2%})\")\n",
        "            if wins > 0:\n",
        "                print(\"‚ö†Ô∏è  Warning: AlphaZero should never win against optimal play!\")\n",
        "            if tie_rate == 1:\n",
        "                print(\"üéâ Excellent! AlphaZero is playing near-optimally!\")\n",
        "\n",
        "        print(\"Training completed!\")\n",
        "        return self.loss_history, self.tie_rate_history\n",
        "\n",
        "def plot_training_progress(loss_history, tie_rate_history):\n",
        "    \"\"\"Plot training progress\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Loss plot\n",
        "    ax1.plot(loss_history)\n",
        "    ax1.set_title('Training Loss')\n",
        "    ax1.set_xlabel('Iteration')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Tie rate plot\n",
        "    iterations = list(range(1, len(tie_rate_history) + 1))\n",
        "    ax2.plot(iterations, [tr * 100 for tr in tie_rate_history], 'b-o')\n",
        "    ax2.axhline(y=100, color='g', linestyle='--', alpha=0.7, label='Perfect play (100% ties)')\n",
        "    ax2.set_title('Tie Rate vs Optimal AI')\n",
        "    ax2.set_xlabel('Iteration')\n",
        "    ax2.set_ylabel('Tie Rate (%)')\n",
        "    ax2.grid(True)\n",
        "    ax2.set_ylim(0, 100)\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def print_board(state):\n",
        "    symbols = {0: ' ', 1: 'X', -1: 'O'}\n",
        "    board_str = \"\"\n",
        "    for i in range(3):\n",
        "        row = \" | \".join([symbols[state[i, j]] for j in range(3)])\n",
        "        board_str += row + \"\\n\"\n",
        "        if i < 2:\n",
        "            board_str += \"---------\\n\"\n",
        "    print(board_str)\n",
        "\n",
        "def demo_game():\n",
        "    \"\"\"Demo game between trained AlphaZero and Optimal AI and evaluate specific state\"\"\"\n",
        "    print(\"\\n=== Demo Game and Evaluation ===\")\n",
        "    trainer = AlphaZeroTrainer()\n",
        "\n",
        "    # Quick training for demo (reduce iterations for faster demo)\n",
        "    trainer.args.num_iters = 5 # Reduced iterations\n",
        "    trainer.args.num_eps = 50 # Reduced episodes\n",
        "    trainer.args.num_mcts_sims = 100 # Reduced simulations per move\n",
        "\n",
        "    print(\"Training AlphaZero (reduced for demo)...\")\n",
        "    loss_history, tie_rate_history = trainer.learn()\n",
        "\n",
        "    # Evaluate the specific state requested by the user\n",
        "    print(\"\\n=== Evaluating specific state: X in the center ===\")\n",
        "    specific_state = np.zeros((3, 3), dtype=np.int8)\n",
        "    specific_state[1, 1] = 1 # Place 'X' in the center\n",
        "    current_player = -1 # It's 'O''s turn (Optimal AI)\n",
        "\n",
        "    print(\"Specific state:\")\n",
        "    print_board(specific_state)\n",
        "\n",
        "    # Get AlphaZero's move prediction for this state\n",
        "    print(\"AlphaZero's move prediction:\")\n",
        "    trainer.nnet.eval() # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        # Ensure input tensor has the correct shape (batch, channels, height, width)\n",
        "        state_tensor = torch.FloatTensor(specific_state).unsqueeze(0).unsqueeze(0).to(device)\n",
        "        log_pi, v = trainer.nnet(state_tensor)\n",
        "        pi = torch.exp(log_pi).cpu().numpy()[0]\n",
        "\n",
        "    valid_moves = trainer.game.get_valid_moves(specific_state)\n",
        "    masked_pi = pi * valid_moves\n",
        "    print(\"Predicted policy (probabilities for each move):\")\n",
        "    print(masked_pi.reshape(3, 3))\n",
        "    print(\"Predicted value:\", v.item())\n",
        "\n",
        "    # Determine AlphaZero's suggested move\n",
        "    if np.sum(masked_pi) > 0:\n",
        "        suggested_action = np.argmax(masked_pi)\n",
        "        row, col = suggested_action // 3, suggested_action % 3\n",
        "        print(f\"AlphaZero suggests moving to position {suggested_action} ({row}, {col}).\")\n",
        "        if suggested_action in [0, 2, 6, 8]:\n",
        "             print(\"AlphaZero suggested a corner move, which is optimal.\")\n",
        "        else:\n",
        "             print(\"AlphaZero did NOT suggest a corner move.\")\n",
        "    else:\n",
        "        print(\"No valid moves with non-zero probability predicted by AlphaZero.\")\n",
        "\n",
        "\n",
        "    print(\"\\n=== Demo Game Play ===\")\n",
        "    state = trainer.game.get_initial_state()\n",
        "    current_player = 1\n",
        "\n",
        "    print(\"Board positions:\")\n",
        "    print(\"0 | 1 | 2\")\n",
        "    print(\"3 | 4 | 5\")\n",
        "    print(\"6 | 7 | 8\")\n",
        "    print()\n",
        "\n",
        "    move_count = 0\n",
        "    while True:\n",
        "        move_count += 1\n",
        "        print(f\"Move {move_count}:\")\n",
        "        print_board(state)\n",
        "\n",
        "        if current_player == 1:\n",
        "            print(\"AlphaZero (X) thinking...\")\n",
        "            mcts = MCTS(trainer.game, trainer.nnet, trainer.args)\n",
        "            canonical_state = trainer.game.get_canonical_form(state, current_player)\n",
        "            # Get action probabilities with temp=0 for deterministic play\n",
        "            pi, _ = mcts.get_action_prob(canonical_state, temp=0)\n",
        "            action = np.argmax(pi)\n",
        "            print(f\"AlphaZero chooses position {action}\")\n",
        "        else:\n",
        "            print(\"Optimal AI (O) thinking...\")\n",
        "            action = trainer.optimal_ai.get_best_move(state, current_player)\n",
        "            print(f\"Optimal AI chooses position {action}\")\n",
        "\n",
        "        state, current_player = trainer.game.get_next_state(state, action, current_player)\n",
        "\n",
        "        result = trainer.game.get_game_ended(state, 1) # Evaluate from player 1's perspective\n",
        "        if result is not None:\n",
        "            print(\"\\nFinal board:\")\n",
        "            print_board(state)\n",
        "            if result == 1:\n",
        "                print(\"AlphaZero (X) wins!\")\n",
        "            elif result == -1:\n",
        "                print(\"Optimal AI (O) wins!\")\n",
        "            else:\n",
        "                print(\"It's a draw!\")\n",
        "            break\n",
        "\n",
        "        print()\n",
        "\n",
        "    # Plot training progress\n",
        "    plot_training_progress(loss_history, tie_rate_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run the demo\n",
        "    demo_game()"
      ],
      "metadata": {
        "id": "pXKHqICBwMw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ad2a8a3-1f12-4971-d516-10a4cca81c60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Demo Game and Evaluation ===\n",
            "Precomputing optimal moves for all positions...\n",
            "Precomputed 4520 positions\n",
            "Training AlphaZero (reduced for demo)...\n",
            "Starting AlphaZero training...\n",
            "\n",
            "=== Iteration 1/5 ===\n",
            "Collecting self-play games...\n",
            "Episode 10/50\n",
            "Episode 20/50\n",
            "Episode 30/50\n",
            "Episode 40/50\n",
            "Episode 50/50\n",
            "Training on 3392 examples...\n",
            "Average loss: 1.4758\n",
            "Evaluating against optimal AI...\n",
            "Results: 0W-10D-0L (Tie rate: 100.00%)\n",
            "üéâ Excellent! AlphaZero is playing near-optimally!\n",
            "\n",
            "=== Iteration 2/5 ===\n",
            "Collecting self-play games...\n",
            "Episode 10/50\n",
            "Episode 20/50\n",
            "Episode 30/50\n",
            "Episode 40/50\n",
            "Episode 50/50\n",
            "Training on 6944 examples...\n",
            "Average loss: 1.3148\n",
            "Evaluating against optimal AI...\n",
            "Results: 0W-10D-0L (Tie rate: 100.00%)\n",
            "üéâ Excellent! AlphaZero is playing near-optimally!\n",
            "\n",
            "=== Iteration 3/5 ===\n",
            "Collecting self-play games...\n",
            "Episode 10/50\n",
            "Episode 20/50\n",
            "Episode 30/50\n",
            "Episode 40/50\n",
            "Episode 50/50\n",
            "Training on 10496 examples...\n",
            "Average loss: 1.2923\n",
            "Evaluating against optimal AI...\n",
            "Results: 0W-10D-0L (Tie rate: 100.00%)\n",
            "üéâ Excellent! AlphaZero is playing near-optimally!\n",
            "\n",
            "=== Iteration 4/5 ===\n",
            "Collecting self-play games...\n",
            "Episode 10/50\n",
            "Episode 20/50\n",
            "Episode 30/50\n",
            "Episode 40/50\n",
            "Episode 50/50\n",
            "Training on 14072 examples...\n",
            "Average loss: 1.2696\n",
            "Evaluating against optimal AI...\n",
            "Results: 0W-10D-0L (Tie rate: 100.00%)\n",
            "üéâ Excellent! AlphaZero is playing near-optimally!\n",
            "\n",
            "=== Iteration 5/5 ===\n",
            "Collecting self-play games...\n",
            "Episode 10/50\n",
            "Episode 20/50\n",
            "Episode 30/50\n",
            "Episode 40/50\n",
            "Episode 50/50\n",
            "Training on 17648 examples...\n",
            "Average loss: 1.2571\n",
            "Evaluating against optimal AI...\n",
            "Results: 0W-10D-0L (Tie rate: 100.00%)\n",
            "üéâ Excellent! AlphaZero is playing near-optimally!\n",
            "Training completed!\n",
            "\n",
            "=== Evaluating specific state: X in the center ===\n",
            "Specific state:\n",
            "  |   |  \n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "  |   |  \n",
            "\n",
            "AlphaZero's move prediction:\n",
            "Predicted policy (probabilities for each move):\n",
            "[[0.1115486  0.12286604 0.1009127 ]\n",
            " [0.11694897 0.         0.13424183]\n",
            " [0.13678424 0.13238016 0.14429204]]\n",
            "Predicted value: -0.08797014504671097\n",
            "AlphaZero suggests moving to position 8 (2, 2).\n",
            "AlphaZero suggested a corner move, which is optimal.\n",
            "\n",
            "=== Demo Game Play ===\n",
            "Board positions:\n",
            "0 | 1 | 2\n",
            "3 | 4 | 5\n",
            "6 | 7 | 8\n",
            "\n",
            "Move 1:\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "\n",
            "AlphaZero (X) thinking...\n",
            "AlphaZero chooses position 6\n",
            "\n",
            "Move 2:\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "X |   |  \n",
            "\n",
            "Optimal AI (O) thinking...\n",
            "Optimal AI chooses position 0\n",
            "\n",
            "Move 3:\n",
            "O |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "X |   |  \n",
            "\n",
            "AlphaZero (X) thinking...\n",
            "AlphaZero chooses position 8\n",
            "\n",
            "Move 4:\n",
            "O |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "X |   | X\n",
            "\n",
            "Optimal AI (O) thinking...\n",
            "Optimal AI chooses position 7\n",
            "\n",
            "Move 5:\n",
            "O |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "X | O | X\n",
            "\n",
            "AlphaZero (X) thinking...\n",
            "AlphaZero chooses position 1\n",
            "\n",
            "Move 6:\n",
            "O | X |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "X | O | X\n",
            "\n",
            "Optimal AI (O) thinking...\n",
            "Optimal AI chooses position 2\n",
            "\n",
            "Move 7:\n",
            "O | X | O\n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "X | O | X\n",
            "\n",
            "AlphaZero (X) thinking...\n",
            "AlphaZero chooses position 4\n",
            "\n",
            "Move 8:\n",
            "O | X | O\n",
            "---------\n",
            "  | X |  \n",
            "---------\n",
            "X | O | X\n",
            "\n",
            "Optimal AI (O) thinking...\n",
            "Optimal AI chooses position 3\n",
            "\n",
            "Move 9:\n",
            "O | X | O\n",
            "---------\n",
            "O | X |  \n",
            "---------\n",
            "X | O | X\n",
            "\n",
            "AlphaZero (X) thinking...\n",
            "AlphaZero chooses position 5\n",
            "\n",
            "Final board:\n",
            "O | X | O\n",
            "---------\n",
            "O | X | X\n",
            "---------\n",
            "X | O | X\n",
            "\n",
            "It's a draw!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYtziK4ovQmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}